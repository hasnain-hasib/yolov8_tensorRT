{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir yolov8-tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov8-tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ultralytics\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorrt\n",
    "!pip install tensorrt_lean\n",
    "!pip install tensorrt_dispatch\n",
    "import tensorrt\n",
    "print(tensorrt.__version__)\n",
    "assert tensorrt.Builder(tensorrt.Logger())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo export model=yolov8s.pt format=engine half=True device=0 workspace=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo detect predict model=yolov8s.engine source=\"https://ultralytics.com/images/bus.jpg\" device=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "image2 = Image.open(\"runs/detect/predict2/bus.jpg\")\n",
    "\n",
    "w, h = image.size\n",
    "\n",
    "new_height = int(h/2)\n",
    "\n",
    "\n",
    "image= image.resize((new_width, new_height))\n",
    "\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mAP Calculation \n",
    "!yolo detect val model=yolov8s.engine data=coco128.yaml iou=0.5 imgsz=640 name=yolov8s-tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/uc?id=1RskX1wXVF0xSMAPgpkU-EsaUv8tD7lvS\n",
    "!unzip modules.zip\n",
    "!mkdir inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "import pathlib\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import modules.utils as utils\n",
    "from modules.autobackend import AutoBackend\n",
    "\n",
    "def tensorrt_detection(model, source, image):\n",
    "    # Preprocess\n",
    "    im = utils.preprocess(image)\n",
    "\n",
    "    # Inference\n",
    "    preds = model(im)\n",
    "\n",
    "    # Post Process\n",
    "    results = utils.postprocess(preds, im, image, model.names, source)\n",
    "    d = results[0].boxes\n",
    "\n",
    "    # Get information from result\n",
    "    tensor_size = d.cls.size()[0]\n",
    "    if(tensor_size > 1):\n",
    "        cls, conf, box = d.cls.squeeze(), d.conf.squeeze(), d.xyxy.squeeze()\n",
    "    else:\n",
    "        cls, conf, box = d.cls, d.conf, d.xyxy\n",
    "\n",
    "    return cls, conf, box\n",
    "\n",
    "def yolov8_detection(model, image):\n",
    "    # Update object localizer\n",
    "    results = model.predict(image, imgsz=640, conf=0.5, verbose=False)\n",
    "    result = results[0].cpu()\n",
    "\n",
    "    # Get information from result\n",
    "    box = result.boxes.xyxy.numpy()\n",
    "    conf = result.boxes.conf.numpy()\n",
    "    cls = result.boxes.cls.numpy().astype(int)\n",
    "\n",
    "    return cls, conf, box\n",
    "\n",
    "def detection(model_path, source, name):\n",
    "  # Check File Extension\n",
    "  file_extension = pathlib.Path(model_path).suffix\n",
    "\n",
    "  if(file_extension == \".engine\"):\n",
    "    model = AutoBackend(model_path, device=torch.device('cuda:0'), fp16=True)\n",
    "    # Warmup\n",
    "    model.warmup()\n",
    "  else:\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "  # Class Name and Colors\n",
    "  label_map = model.names\n",
    "  COLORS = [[random.randint(0, 255) for _ in range(3)] for _ in label_map]\n",
    "\n",
    "  # FPS Detection\n",
    "  frame_count = 0\n",
    "  total_fps = 0\n",
    "  avg_fps = 0\n",
    "\n",
    "  # FPS Video\n",
    "  video_cap = cv2.VideoCapture(source)\n",
    "\n",
    "  total_frames = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "  frame_width = int(video_cap.get(3))\n",
    "  frame_height = int(video_cap.get(4))\n",
    "\n",
    "  video_frames = []\n",
    "\n",
    "  while video_cap.isOpened():\n",
    "      ret, frame = video_cap.read()\n",
    "      if not ret:\n",
    "          break\n",
    "\n",
    "      # # Start Time\n",
    "      start = time.time()\n",
    "\n",
    "      # Detection\n",
    "      if(file_extension == \".engine\"):\n",
    "        cls, conf, box = tensorrt_detection(model, source, frame)\n",
    "      else:\n",
    "        cls, conf, box = yolov8_detection(model, frame)\n",
    "\n",
    "      # Pack together for easy use\n",
    "      detection_output = list(zip(cls, conf, box))\n",
    "      image_output = utils.draw_box(frame, detection_output, label_map, COLORS)\n",
    "\n",
    "      end = time.time()\n",
    "      # # End Time\n",
    "\n",
    "      # Draw FPS\n",
    "      frame_count += 1\n",
    "      fps = 1 / (end - start)\n",
    "      total_fps = total_fps + fps\n",
    "      avg_fps = total_fps / frame_count\n",
    "\n",
    "      image_output = utils.draw_fps(avg_fps, image_output)\n",
    "\n",
    "      # Append frame to array\n",
    "      video_frames.append(image_output)\n",
    "\n",
    "      #\n",
    "      print(\"(%2d / %2d) Frames Processed\" % (frame_count, total_frames))\n",
    "\n",
    "  print(avg_fps)\n",
    "\n",
    "  # Get a file name\n",
    "  file_name = utils.get_name(source)\n",
    "  # Get Save Path\n",
    "  folder_name = name\n",
    "  save_path = utils.get_save_path(file_name, folder_name)\n",
    "  # Create VideoWriter object.\n",
    "  out = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'XVID'), int(avg_fps), (frame_width, frame_height))\n",
    "\n",
    "  for frame in video_frames:\n",
    "      out.write(frame)\n",
    "\n",
    "  out.release()\n",
    "\n",
    "  print(\"Video is saved in: \"+save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection(\"yolov8s.engine\", \"inference/people.mp4\", \"detection\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
